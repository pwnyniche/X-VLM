{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "# from models.model_nlvr import XVLM\n",
    "from models.model_pretrain import XVLM\n",
    "from models import XVLMBase, build_mlp, load_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.distributed as dist\n",
    "#dist.init_process_group('gloo', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_file': ['data/finetune/cosmos_caption_train.json'], 'val_file': ['data/finetune/cosmos_caption_val.json'], \n",
    "'test_file': ['data/finetune/cosmos_caption_val.json'], \n",
    "'image_root': 'images/cosmos/', 'vision_config': 'configs/config_swinB_384.json', \n",
    "'use_clip_vit': False, 'use_swin': True, 'image_res': 384, 'patch_size': 32, \n",
    "'use_roberta': False, 'text_config': 'configs/config_bert.json', \n",
    "'text_encoder': 'data/bert-base-uncased', 'batch_size_train': 20, \n",
    "'batch_size_test': 12, 'batch_size_test_text': 64, 'max_tokens': 40, 'embed_dim': 256, \n",
    "'temp': 0.07, 'k_test': 256, 'optimizer': {'opt': 'adamW', 'lr': 3e-05, 'weight_decay': 0.01, \n",
    "'lr_mult': 2}, 'schedular': {'sched': 'linear', 'lr': 3e-05, 'epochs': 10, 'num_warmup_steps': 0.1},\n",
    "'prompt':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position interpolate layers.0.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.0.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.1.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.1.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.2.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.3.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.4.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.5.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.6.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.7.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.8.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.9.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.10.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.11.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.12.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.13.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.14.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.15.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.16.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.2.blocks.17.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.3.blocks.0.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "Position interpolate layers.3.blocks.1.attn.relative_position_bias_table from 13x13 to 23x23\n",
      "### Load ViT: \n",
      "missing_keys:  ['layers.0.blocks.0.attn.relative_position_index', 'layers.0.blocks.1.attn_mask', 'layers.0.blocks.1.attn.relative_position_index', 'layers.1.blocks.0.attn.relative_position_index', 'layers.1.blocks.1.attn_mask', 'layers.1.blocks.1.attn.relative_position_index', 'layers.2.blocks.0.attn.relative_position_index', 'layers.2.blocks.1.attn_mask', 'layers.2.blocks.1.attn.relative_position_index', 'layers.2.blocks.2.attn.relative_position_index', 'layers.2.blocks.3.attn_mask', 'layers.2.blocks.3.attn.relative_position_index', 'layers.2.blocks.4.attn.relative_position_index', 'layers.2.blocks.5.attn_mask', 'layers.2.blocks.5.attn.relative_position_index', 'layers.2.blocks.6.attn.relative_position_index', 'layers.2.blocks.7.attn_mask', 'layers.2.blocks.7.attn.relative_position_index', 'layers.2.blocks.8.attn.relative_position_index', 'layers.2.blocks.9.attn_mask', 'layers.2.blocks.9.attn.relative_position_index', 'layers.2.blocks.10.attn.relative_position_index', 'layers.2.blocks.11.attn_mask', 'layers.2.blocks.11.attn.relative_position_index', 'layers.2.blocks.12.attn.relative_position_index', 'layers.2.blocks.13.attn_mask', 'layers.2.blocks.13.attn.relative_position_index', 'layers.2.blocks.14.attn.relative_position_index', 'layers.2.blocks.15.attn_mask', 'layers.2.blocks.15.attn.relative_position_index', 'layers.2.blocks.16.attn.relative_position_index', 'layers.2.blocks.17.attn_mask', 'layers.2.blocks.17.attn.relative_position_index', 'layers.3.blocks.0.attn.relative_position_index', 'layers.3.blocks.1.attn.relative_position_index']\n",
      "unexpected_keys:  ['head.weight', 'head.bias']\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py:1359\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1357'>1358</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1358'>1359</a>\u001b[0m     state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(resolved_archive_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1359'>1360</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py:608\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=606'>607</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=607'>608</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py:777\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=771'>772</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=772'>773</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=773'>774</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=774'>775</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=776'>777</a>\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39;49mload(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/serialization.py?line=777'>778</a>\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/root/thesis/X-VLM/retrevial.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m XVLM(config\u001b[39m=\u001b[39;49mconfig)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mload_pretrained(\u001b[39m'\u001b[39m\u001b[39mcheckpoint/4m_base_model_state_step_199999.th\u001b[39m\u001b[39m'\u001b[39m, config, is_eval\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000003vscode-remote?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/thesis/X-VLM/models/model_pretrain.py:7\u001b[0m, in \u001b[0;36mXVLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m      <a href='file:///root/thesis/X-VLM/models/model_pretrain.py?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n\u001b[0;32m----> <a href='file:///root/thesis/X-VLM/models/model_pretrain.py?line=6'>7</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config, load_vision_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, load_text_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='file:///root/thesis/X-VLM/models/model_pretrain.py?line=7'>8</a>\u001b[0m                      use_contrastive_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, use_matching_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, use_mlm_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, use_bbox_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, config_text\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/thesis/X-VLM/models/xvlm.py:272\u001b[0m, in \u001b[0;36mXVLMBase.__init__\u001b[0;34m(self, config, load_vision_params, load_text_params, use_contrastive_loss, use_matching_loss, use_mlm_loss, use_bbox_loss, config_text)\u001b[0m\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=267'>268</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_params \u001b[39m=\u001b[39m []  \u001b[39m# train from scratch with larger lr\u001b[39;00m\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=269'>270</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvision_encoder, vision_width \u001b[39m=\u001b[39m build_vision_encoder(config, load_params\u001b[39m=\u001b[39mload_vision_params)\n\u001b[0;32m--> <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=271'>272</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_encoder, init_params \u001b[39m=\u001b[39m build_text_encoder(config, vision_width\u001b[39m=\u001b[39;49mvision_width, load_text_params\u001b[39m=\u001b[39;49mload_text_params,\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=272'>273</a>\u001b[0m                                                     use_mlm_loss\u001b[39m=\u001b[39;49muse_mlm_loss,\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=273'>274</a>\u001b[0m                                                     config_text\u001b[39m=\u001b[39;49mconfig_text)  \u001b[39m# text & cross-modal\u001b[39;00m\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=274'>275</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_params\u001b[39m.\u001b[39mextend(init_params)\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=276'>277</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvision_width \u001b[39m=\u001b[39m vision_width\n",
      "File \u001b[0;32m~/thesis/X-VLM/models/xvlm.py:163\u001b[0m, in \u001b[0;36mbuild_text_encoder\u001b[0;34m(config, vision_width, load_text_params, use_mlm_loss, config_text)\u001b[0m\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=159'>160</a>\u001b[0m     text_encoder, msg \u001b[39m=\u001b[39m RobertaForMaskedLM\u001b[39m.\u001b[39mfrom_pretrained(config[\u001b[39m'\u001b[39m\u001b[39mtext_encoder\u001b[39m\u001b[39m'\u001b[39m], config\u001b[39m=\u001b[39mconfig_text,\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=160'>161</a>\u001b[0m                                                            output_loading_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=161'>162</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=162'>163</a>\u001b[0m     text_encoder, msg \u001b[39m=\u001b[39m BertForMaskedLM\u001b[39m.\u001b[39;49mfrom_pretrained(config[\u001b[39m'\u001b[39;49m\u001b[39mtext_encoder\u001b[39;49m\u001b[39m'\u001b[39;49m], config\u001b[39m=\u001b[39;49mconfig_text,\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=163'>164</a>\u001b[0m                                                         output_loading_info\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=165'>166</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m### Load BERT: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=166'>167</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m msg\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py:1364\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1361'>1362</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(resolved_archive_file) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1362'>1363</a>\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1363'>1364</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1364'>1365</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou seem to have cloned a repository without having git-lfs installed. Please install \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1365'>1366</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgit-lfs and run `git lfs install` followed by `git lfs pull` in the folder \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1366'>1367</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou cloned.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1367'>1368</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1368'>1369</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/transformers/modeling_utils.py?line=1369'>1370</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You seem to have cloned a repository without having git-lfs installed. Please install git-lfs and run `git lfs install` followed by `git lfs pull` in the folder you cloned."
     ]
    }
   ],
   "source": [
    "model = XVLM(config=config)\n",
    "model.load_pretrained('checkpoint/4m_base_model_state_step_199999.th', config, is_eval=True)\n",
    "model = model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torchvision/transforms/transforms.py:834: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_dataset('caption_cosmos', config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[train_dataset, val_dataset, test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_loader(datasets, [None, None, None], batch_size=[5,5,5],\n",
    "                                                          num_workers=[4, 4, 4], is_trains=[True, False, False],\n",
    "                                                          collate_fns=[None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tokenization_bert import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "tokenizer = BertTokenizer.from_pretrained(config['text_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zz\n",
      "tensor(-0., device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (sum of probabilities <= 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/thesis/X-VLM/retrevial.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000006vscode-remote?line=3'>4</a>\u001b[0m idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000006vscode-remote?line=4'>5</a>\u001b[0m text_input \u001b[39m=\u001b[39m tokenizer(text, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlongest\u001b[39m\u001b[39m'\u001b[39m, max_length\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mmax_tokens\u001b[39m\u001b[39m'\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000006vscode-remote?line=6'>7</a>\u001b[0m loss_itc, loss_itm \u001b[39m=\u001b[39m model(image, text_input\u001b[39m.\u001b[39;49minput_ids, text_input\u001b[39m.\u001b[39;49mattention_mask, idx\u001b[39m=\u001b[39;49midx)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.29.64.76/root/thesis/X-VLM/retrevial.ipynb#ch0000006vscode-remote?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_itc \u001b[39m+\u001b[39m loss_itm\n",
      "File \u001b[0;32m~/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/thesis/X-VLM/models/model_retrieval.py:28\u001b[0m, in \u001b[0;36mXVLM.forward\u001b[0;34m(self, image, text_ids, text_atts, idx)\u001b[0m\n\u001b[1;32m     <a href='file:///root/thesis/X-VLM/models/model_retrieval.py?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mzz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///root/thesis/X-VLM/models/model_retrieval.py?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(loss_itc)\n\u001b[0;32m---> <a href='file:///root/thesis/X-VLM/models/model_retrieval.py?line=27'>28</a>\u001b[0m loss_itm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_matching_loss(image_embeds, image_atts, image_feat, text_embeds, text_atts, text_feat, idx\u001b[39m=\u001b[39;49midx)\n\u001b[1;32m     <a href='file:///root/thesis/X-VLM/models/model_retrieval.py?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss_itc, loss_itm\n",
      "File \u001b[0;32m~/thesis/X-VLM/models/xvlm.py:436\u001b[0m, in \u001b[0;36mXVLMBase.get_matching_loss\u001b[0;34m(self, image_embeds, image_atts, image_feat, text_embeds, text_atts, text_feat, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=433'>434</a>\u001b[0m image_atts_neg \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=434'>435</a>\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(bs):\n\u001b[0;32m--> <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=435'>436</a>\u001b[0m     neg_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(weights_t2i[b], \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=436'>437</a>\u001b[0m     image_embeds_neg\u001b[39m.\u001b[39mappend(image_embeds[neg_idx])\n\u001b[1;32m    <a href='file:///root/thesis/X-VLM/models/xvlm.py?line=437'>438</a>\u001b[0m     image_atts_neg\u001b[39m.\u001b[39mappend(image_atts[neg_idx])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (sum of probabilities <= 0)"
     ]
    }
   ],
   "source": [
    "image,text,_=train_dataset[500]\n",
    "idx = torch.tensor(1)\n",
    "image = image[None,:].to('cuda', non_blocking=True)\n",
    "idx = idx.to('cuda', non_blocking=True)\n",
    "text_input = tokenizer(text, padding='longest', max_length=config['max_tokens'], return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "loss_itc, loss_itm = model(image, text_input.input_ids, text_input.attention_mask, idx=idx)\n",
    "loss = loss_itc + loss_itm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43a2aefd9a4740e0597b3489c1c78fca90cd0ffb50c6fc4e233b22791010a45e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('xvlm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
