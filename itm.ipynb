{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataset, create_sampler, create_loader\n",
    "from models.model_retrieval import XVLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train_file': ['data/finetune/cosmos_caption_test.json'], \n",
    "    'val_file': ['data/finetune/cosmos_caption_test.json'], \n",
    "    'test_file': ['data/finetune/cosmos_caption_test.json'],\n",
    "    'image_res': 384,\n",
    "    'image_root': '/root/thesis/dataset',\n",
    "    'prompt':'',\n",
    "    'max_tokens': 4,\n",
    "    'patch_size': 32,\n",
    "    'use_clip_vit': False,\n",
    "    'use_swin':True,\n",
    "    'vision_config': 'configs/config_swinB_384.json',\n",
    "    'use_roberta': False,\n",
    "    'text_config': 'configs/config_bert.json',  # ['configs/config_bert.json', 'configs/config_roberta.json']\n",
    "'text_encoder': 'data/bert-base-uncased' ,\n",
    "'batch_size_train': 20,\n",
    "'batch_size_test': 12,\n",
    "'batch_size_test_text': 64,\n",
    "'max_tokens': 40,\n",
    "'embed_dim': 256,\n",
    "'temp': 0.07,\n",
    "'k_test': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XVLM(config=config)\n",
    "# model.load_pretrained('/root/thesis/X-VLM/checkpoint/checkpoint_best_refcoco.pth', config, is_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tokenization_bert import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "tokenizer = BertTokenizer.from_pretrained(config['text_encoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torchvision/transforms/transforms.py:834: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/xvlm/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_dataset('caption_cosmos', config);\n",
    "datasets = [train_dataset, val_dataset, test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_loader(datasets, [None, None, None], batch_size=[5] * 3,\n",
    "                                                          num_workers=[4, 4, 4], is_trains=[True, False, False],\n",
    "                                                          collate_fns=[None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|██████████| 200/200 [00:39<00:00,  5.29it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "100%|██████████| 200/200 [00:39<00:00,  5.05it/s]\n"
     ]
    }
   ],
   "source": [
    "itc=[]\n",
    "itm=[]\n",
    "for img,cap,label in tqdm(train_loader):\n",
    "    img = img.to(device)\n",
    "    text_inputs = tokenizer(cap, padding='longest', return_tensors=\"pt\",max_length=512, truncation=True).to(device)\n",
    "    pred = model(img,text_inputs.input_ids, text_inputs.attention_mask)\n",
    "    itc.append(pred[0].item())\n",
    "    itm.append(pred[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789966344833374"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(itm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43a2aefd9a4740e0597b3489c1c78fca90cd0ffb50c6fc4e233b22791010a45e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('xvlm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
